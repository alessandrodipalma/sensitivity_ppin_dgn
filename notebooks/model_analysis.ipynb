{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from lightning import Trainer\n",
    "from torchmetrics.functional import accuracy, specificity, auroc, recall, precision, f1_score, matthews_corrcoef\n",
    "from pathlib import Path\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from src.model_development.kfold import *\n",
    "from src.model_development.datamodule import *\n",
    "from src.model_development.dgn.dgn import DGN\n",
    "from src.model_development.dgn.deepsets import DeepSetsModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('../config.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(config[\"ray_results_path\"])\n",
    "trial_names = pickle.load(open(\"gcn_best_trial_names.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project = \"Master-Thesis\"\n",
    "project = \"peppina-final\"\n",
    "# project = \"gnn-ppi-sens\"\n",
    "\n",
    "def find_trial_ckpts(name, project=project):\n",
    "    \n",
    "    # try:\n",
    "    dir = [f for f in base_path.rglob(f\"*{name}*/\")][0]\n",
    "    # except:\n",
    "    #     return None\n",
    "    \n",
    "    config = pickle.load((dir/\"params.pkl\").open(\"rb\"))\n",
    "    paths = [f for f in (dir/project).rglob(f\"*last.ckpt\")]\n",
    "    paths = paths + [f for f in (dir/project).rglob(f\"*.ckpt\")]\n",
    "    \n",
    "    return {\n",
    "        'config': config,\n",
    "        'ckpts': paths\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [02:59<00:00,  5.00s/it]\n"
     ]
    }
   ],
   "source": [
    "ckpts={}\n",
    "for k, name in tqdm(trial_names.items()):\n",
    "    ckpts[k] = find_trial_ckpts(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ray_results/train_gcn_2024-12-05_10-34-29/train_gcn_81de7_00000_0_activation=sigmoid,aggr=add,batch_size=4096,bias=True,bias_scale=0.1000,bn=False,conv=DirGNNConv,dataloade_2024-12-05_10-34-29/peppina-final/1l2ce4ql/checkpoints/last.ckpt\n",
      "/data/ray_results/train_gcn_2024-12-05_10-34-29/train_gcn_81de7_00001_1_activation=sigmoid,aggr=add,batch_size=4096,bias=True,bias_scale=0.1000,bn=False,conv=DirGNNConv,dataloade_2024-12-05_10-34-29/peppina-final/gn6zhovx/checkpoints/last.ckpt\n",
      "/data/ray_results/train_gcn_2024-12-05_10-34-29/train_gcn_81de7_00002_2_activation=sigmoid,aggr=add,batch_size=4096,bias=True,bias_scale=0.1000,bn=False,conv=DirGNNConv,dataloade_2024-12-05_11-01-47/peppina-final/bs3862b7/checkpoints/last.ckpt\n",
      "/data/ray_results/train_gcn_2024-12-02_15-05-07/train_gcn_d1689_00000_0_activation=sigmoid,aggr=add,batch_size=4096,bias=True,bias_scale=0.1000,bn=False,conv=DirGNNConv,dataloade_2024-12-02_15-05-07/peppina-final/s2zd54wp/checkpoints/last.ckpt\n"
     ]
    }
   ],
   "source": [
    "for f in range(4):\n",
    "    print(ckpts[('UC1','128',f)]['ckpts'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 18:57:25,690\tINFO worker.py:1841 -- Started a local Ray instance.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'use_case'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m config\u001b[38;5;241m=\u001b[39mckpts[(hold_out_by, embeddings_len, \u001b[38;5;241m0\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiogrid_ver\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-10\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m folds[(hold_out_by,embeddings_len)] \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_fold_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sensitivity_ppin_dgn/src/model_development/kfold.py:17\u001b[0m, in \u001b[0;36mcreate_fold_dict\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     13\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m (config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings_len\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings_len\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m datalist \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload((data_path\u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyg_datalists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m filename)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_case\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     18\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_case\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grid_search([config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_case\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     20\u001b[0m folds \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'use_case'"
     ]
    }
   ],
   "source": [
    "folds={}\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True, _temp_dir=\"/data/adipalma/tmp\")\n",
    "\n",
    "for hold_out_by in ['UC1','UC2','UC3']:\n",
    "    for embeddings_len in ['0','128']:#,'onehot']:\n",
    "        config=ckpts[(hold_out_by, embeddings_len, 0)]['config']\n",
    "        config['biogrid_ver'] = '2024-10'\n",
    "        folds[(hold_out_by,embeddings_len)] = create_fold_dict(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'specificity': specificity,\n",
    "    'auroc': auroc,\n",
    "    'recall': recall,\n",
    "    'precision': precision,\n",
    "    'f1': f1_score,\n",
    "    'mcc': matthews_corrcoef\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide cuda devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_predict(config, ckpt, hold_out_by, features):\n",
    "\n",
    "    fold = ray.get(folds[(hold_out_by, features)][0]\n",
    "                   [('sensitivity',config['hold_out_by']['grid_search'][0] if type(config['hold_out_by'])==dict else config['hold_out_by'])]\n",
    "                   [config['test_fold']])\n",
    "    \n",
    "    if 'aggr' not in config.keys():\n",
    "        config['aggr'] = config['SAGE_aggr']\n",
    "    if 'uniform_bound' not in config.keys():\n",
    "        config['uniform_bound'] = None\n",
    "    if 'weight_initializer' not in config.keys():\n",
    "        config['weight_initializer'] = 'kaiming_uniform'\n",
    "\n",
    "\n",
    "    test = fold['test']\n",
    "    outer_train = fold['train']\n",
    "    train = outer_train[config[\"val_fold\"]]['train']\n",
    "    val = outer_train[config[\"val_fold\"]]['val']\n",
    "    config['batch_size'] = 10000\n",
    "    \n",
    "    data = GraphDataModule(train, val, test, config)\n",
    "    data.setup()\n",
    "\n",
    "    input_dim = train[0].x.shape[1]\n",
    "    output_dim = 1\n",
    "    start = time.time()\n",
    "\n",
    "    if config['model'] == 'gcn':\n",
    "        model = DGN.load_from_checkpoint(ckpt, input_dim=input_dim, output_dim=output_dim, config=config,  map_location=torch.device('cpu'))\n",
    "    elif config['model'] == 'deepsets':\n",
    "        model = DeepSetsModule.load_from_checkpoint(ckpt, input_dim=input_dim, output_dim=output_dim, config=config,  map_location=torch.device('cpu'))\n",
    "    \n",
    "    cuda_args = {\"accelerator\": \"cpu\"}\n",
    "\n",
    "    trainer = Trainer(enable_progress_bar = False, **cuda_args)\n",
    "  \n",
    "    data = GraphDataModule(train, val, test, config)\n",
    "    data.setup()\n",
    "    end = time.time()\n",
    "    print(\"Time to load model: \", end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    predictions = trainer.predict(model, data.test_dataloader())\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Time to predict: \", end-start)\n",
    "    # concatenate all predictions in a single tensor\n",
    "    predictions = torch.cat(predictions)\n",
    "    \n",
    "    return predictions, data.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}\n",
    "for k,v in ckpts.items():\n",
    "\n",
    "    predictions_dict[k] = {}\n",
    "    if len(v['ckpts']) == 0:\n",
    "        print(f\"no checkpoint for {k} fold {k[2]}\")\n",
    "    try:\n",
    "        predictions = load_and_predict(v['config'], v['ckpts'][-1], k[0], k[1])\n",
    "        predictions_dict[k] = predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"error for {k} fold {k[2]}\")\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(predictions_dict, open(\"predictions_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict=pickle.load(open(\"predictions_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(predictions, test, confidence_threshold=None):\n",
    "    stats = []\n",
    "    # print(len(predictions), len(test))\n",
    "    # print(type(test))\n",
    "    if confidence_threshold is not None:\n",
    "        probs = torch.sigmoid(predictions)\n",
    "        index = [i for i, p in enumerate(probs) if p < confidence_threshold or p > (1-confidence_threshold)]\n",
    "        test = [test[i] for i in index]   \n",
    "        predictions = predictions[index]     \n",
    "        if len(index) == 0:\n",
    "            print(\"no predictions\")\n",
    "            return None\n",
    "    \n",
    "    for i,d in enumerate(test):\n",
    "        if i >= len(predictions):\n",
    "            break\n",
    "        # convert the graph to networkx\n",
    "        g = to_networkx(d, remove_self_loops=True)\n",
    "        # print(g.edges())\n",
    "        # print(d['x'])\n",
    "        input_node = np.where(d['x'][:,0]==1)[0][0]\n",
    "        output_node = np.where(d['x'][:,1]==1)[0][0]\n",
    "        # print(input_node, output_node)\n",
    "        \n",
    "        def distance(g, input_node, output_node):\n",
    "            try: \n",
    "                return nx.shortest_path_length(g, source=input_node, target=output_node)\n",
    "            except: \n",
    "                return 0\n",
    "\n",
    "        stats.append({\n",
    "            'nodes': d['x'].shape[0],\n",
    "            'edges': d['edge_index'].shape[1] if d['edge_index'].shape[0] == 2 else 0,\n",
    "            'cc': nx.average_clustering(g),\n",
    "            'distance_io': distance(g, input_node, output_node),\n",
    "            'distance_oi': distance(g, output_node, input_node),\n",
    "            'input_centrality': nx.degree_centrality(g)[input_node],\n",
    "            'output_centrality': nx.degree_centrality(g)[output_node],\n",
    "        })\n",
    "\n",
    "    assert len(stats)==len(predictions)\n",
    "    df = pd.DataFrame(stats)\n",
    "    return df\n",
    "\n",
    "\n",
    "def metrics_from_predictions(predictions, test, confidence_threshold=None):\n",
    "    \n",
    "    df = compute_stats(predictions, test, confidence_threshold)\n",
    "    \n",
    "    metrics_dict = {}\n",
    "    print(len(predictions), len(test))\n",
    "    for metric_name, fun in {'f1': f1_score, 'mcc': matthews_corrcoef}.items():\n",
    "        metrics_dict[metric_name] = {}\n",
    "        \n",
    "        all_labels = torch.IntTensor([d['y'] for d in test])\n",
    "        print(all_labels.shape)\n",
    "        def apply_metric(x):\n",
    "            preds = predictions[x.index]\n",
    "            labels = all_labels[x.index]\n",
    "            # labels = d['y']\n",
    "            \n",
    "            \n",
    "            return fun(preds, torch.IntTensor(labels), task='binary')\n",
    "        \n",
    "        metrics_dict[metric_name]['mean'] = apply_metric(df)\n",
    "        print(metrics_dict[metric_name]['mean'])\n",
    "        \n",
    "        for grouping, bins in {\n",
    "            'nodes': range(0, df.nodes.max(), 5),\n",
    "            'edges': range(0, df.edges.max(), 20),\n",
    "            'cc': [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "            'distance_io': range(8),\n",
    "            'distance_oi': range(8),\n",
    "        }.items():\n",
    "            if grouping not in ['distance_io', 'distance_oi']:\n",
    "                df[f\"{grouping}_bin\"] = pd.cut(df[grouping], bins=bins)\n",
    "                # set the bin id as the center of the bin\n",
    "                df[\"bin_id\"] = df[f\"{grouping}_bin\"].apply(lambda x: x.mid).astype(float)\n",
    "                metrics_dict[metric_name][f'by_{grouping}'] = df.groupby(\"bin_id\").apply(apply_metric)\n",
    "            else:\n",
    "                metrics_dict[metric_name][f'by_{grouping}'] = df.groupby(grouping).apply(apply_metric)\n",
    "            \n",
    "\n",
    "    # print(by_nodes)\n",
    "\n",
    "    return metrics_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dicts = {}\n",
    "for k, v in predictions_dict.items():\n",
    "    if k[1] =='onehot':\n",
    "        continue\n",
    "    metrics_dicts[k]= {}\n",
    "    print(k)\n",
    "    try:\n",
    "        # print(predictions_dict[k])\n",
    "        metrics_dicts[k], df = metrics_from_predictions(*predictions_dict[k])    \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(metrics_dicts, open(\"metrics_dicts.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dicts = pickle.load(open(\"metrics_dicts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most significant plots (export for article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance w.r.t. CC, nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_fonts(ax, skip_artists=2):\n",
    "    ax.legend(['I/O', 'I/O+emb', '',''])\n",
    "    artists = ax.legend_.legendHandles\n",
    "    # remove the error bars from the legend\n",
    "    artists = [artist for i, artist in enumerate(artists) if i%skip_artists==0]\n",
    "    ax.legend(artists, ['I/O', 'I/O+emb'], loc='upper right', prop={'size': 20}, )\n",
    "    # set the legend background alpha\n",
    "    ax.legend_.get_frame().set_alpha(0.4)\n",
    "\n",
    "    # increase the font of axis labels and legend\n",
    "    for item in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(16)\n",
    "    for item in [ax.title, ax.xaxis.label, ax.yaxis.label]:\n",
    "        item.set_fontsize(24)\n",
    "    # avoid cutting exis title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mcc w.r.t. the number of nodes, edges and cc with a regplot\n",
    "# for by in ['by_nodes', 'by_edges', 'by_cc']:\n",
    "for by in ['by_cc','by_nodes','by_edges']:\n",
    "    for metric in ['mcc']:\n",
    "        for hold_out_by in ['UC1','UC2','UC3']:\n",
    "            fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "            for embeddings_len in ['0', '128']:\n",
    "                data=[]\n",
    "                for fold in range(4):\n",
    "                    data.append(metrics_dicts[(hold_out_by,embeddings_len,fold)][metric][by].sort_index())\n",
    "                data = pd.concat(data, axis=1)\n",
    "                data = data.mean(axis=1)\n",
    "\n",
    "                sns.regplot(x=data.index, y=np.array(data, dtype=float), ax=ax, order=2)\n",
    "                \n",
    "                ax.set_ylim([0,1])\n",
    "                ax.set_ylabel(metric.upper())\n",
    "                ax.set_xlabel(by.replace('by_',''))\n",
    "                \n",
    "                if by == 'by_cc':\n",
    "                    ax.set_xlim([0,1])\n",
    "                elif by == 'by_nodes':\n",
    "                    ax.set_xlim([2,None])\n",
    "                elif by == 'by_edges':\n",
    "                    ax.set_xlim([1,None])\n",
    "\n",
    "                fig.tight_layout(pad=3.0)\n",
    "                \n",
    "            set_fonts(ax, skip_artists=3)\n",
    "            plt.savefig(f'figures/{metric}_{by}_{hold_out_by}.pdf', format='pdf')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mcc w.r.t. the number of nodes, edges and cc with a regplot\n",
    "for by in ['by_nodes', 'by_edges']:\n",
    "    for metric in ['f1']:\n",
    "        for hold_out_by in ['UC1','UC2','UC3']:\n",
    "            fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "            for embeddings_len in ['0', '128']:\n",
    "                data=[]\n",
    "                for fold in (range(4) if not (hold_out_by=='UC1' and embeddings_len=='0') else [0,1,2]):\n",
    "                    data.append(metrics_dicts[(hold_out_by,embeddings_len,fold)][metric][by].sort_index())\n",
    "                data = pd.concat(data, axis=1)\n",
    "                data = data.mean(axis=1)\n",
    "                # group samples in bins\n",
    "                data = data.groupby(pd.cut(data.index, bins=20)).mean()\n",
    "                # convert the intevals in the middle of the interval\n",
    "                data.index = [(i.left+i.right)/2 for i in data.index]\n",
    "                # sns.regplot(x=data.index, y=np.array(data, dtype=float), ax=ax, order=2)\n",
    "                # plot the moving average\n",
    "                avg_data = data.rolling(window=3)\n",
    "                # smooth the data\n",
    "                ax.plot(avg_data.mean())\n",
    "                # plot also the standard deviation of the moving average\n",
    "                ax.fill_between(data.index, avg_data.mean() - avg_data.std(), avg_data.mean() + avg_data.std(), alpha=0.2)\n",
    "                ax.set_ylabel(metric.upper())\n",
    "                ax.set_xlabel(by.replace('by_',''))\n",
    "                # ax.set_title(f'{metric} w.r.t. {by}')\n",
    "\n",
    "                fig.tight_layout(pad=3.0)\n",
    "                \n",
    "            set_fonts(ax)\n",
    "            plt.savefig(f'figures_2024-10/f1_{by}_{hold_out_by}.pdf', format='pdf')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance w.r.t. I->O and O->I distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the f1 score w.r.t. I->O distance one a line plot, averaging over the folds and showing the standard deviation\n",
    "for direction in ['io', 'oi']:\n",
    "    for hold_out_by in ['UC1','UC2','UC3']:\n",
    "        for metric in ['f1','mcc']:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "            for embeddings_len in ['0', '128']:\n",
    "                data = []\n",
    "                for fold in range(4):\n",
    "                    data.append(metrics_dicts[(hold_out_by,embeddings_len,fold)]['f1'][f'by_distance_{direction}'].sort_index())\n",
    "                data = pd.concat(data, axis=1)\n",
    "                means = data.mean(axis=1).sort_index()\n",
    "                stds =  data.std(axis=1).sort_index()\n",
    "                # ax.plot(means, label=k)\n",
    "                # replace inf and nans with 0\n",
    "                index = means.index\n",
    "                stds = np.array(stds, dtype=float)\n",
    "                means = np.array(means, dtype=float)\n",
    "                # ax.fill_between(index, means - stds, means + stds, alpha=0.2)\n",
    "                ax.set_ylim([0,1.1])\n",
    "                # ax.set_title(f'f1 w.r.t. I->O distance')\n",
    "                ax.set_ylabel('F1')\n",
    "                fig.tight_layout(pad=3.0)\n",
    "                # increase font size\n",
    "                ax.set_xlim([1,7])\n",
    "                \n",
    "                sns.regplot(x=index, y=means, ax=ax, scatter=True, order=2)\n",
    "                ax.set_xlabel('Path length from $u_{in}$ to $u_{out}$')\n",
    "            \n",
    "            set_fonts(ax, skip_artists=3)\n",
    "            \n",
    "            plt.savefig(f'figures_2024-10/{metric}_by_distance_{direction}_{hold_out_by}.pdf', format='pdf')\n",
    "            plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyppin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
