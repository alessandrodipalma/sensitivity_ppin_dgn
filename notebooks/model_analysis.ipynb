{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/2024-10/code/gnn_on_ppi/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\n\u001b[1;32m     17\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../src\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_development\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkfold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_development\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/2024-10/code/gnn_on_ppi/src/model_development/kfold.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtune\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grid_search\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 9\u001b[0m data_path \u001b[38;5;241m=\u001b[39m Path(osp\u001b[38;5;241m.\u001b[39mexpanduser(json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_fold_dict\u001b[39m(config):\n\u001b[1;32m     13\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph_classification_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings_len\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from lightning import Trainer\n",
    "from torchmetrics.functional import accuracy, specificity, auroc, recall, precision, f1_score, matthews_corrcoef\n",
    "from pathlib import Path\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import ray\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "from model_development.kfold import *\n",
    "from model_development.datamodule import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('../config.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'ray_results_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mray_results_path\u001b[49m\n\u001b[1;32m      2\u001b[0m trial_names \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model_selection/gcn_2024-4_best_trial_names.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'ray_results_path'"
     ]
    }
   ],
   "source": [
    "base_path = config.ray_results_path\n",
    "trial_names = pickle.load(open(\"../model_selection/gcn_2024-4_best_trial_names.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:04<01:51,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '0', 0) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:08<01:31,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '0', 1) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [00:12<01:21,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '0', 2) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:15<01:16,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '0', 3) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [00:19<01:11,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '128', 0) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6/24 [00:23<01:07,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '128', 1) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [00:26<01:03,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '128', 2) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [00:30<00:59,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC1', '128', 3) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 9/24 [00:35<00:59,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '0', 0) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 10/24 [00:38<00:54,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '0', 1) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:43<00:53,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '0', 2) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 12/24 [00:47<00:47,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '0', 3) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 13/24 [00:50<00:42,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '128', 0) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 14/24 [00:54<00:37,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '128', 1) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 15/24 [00:57<00:33,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '128', 2) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [01:01<00:29,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC2', '128', 3) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [01:05<00:25,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '0', 0) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [01:08<00:22,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '0', 1) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19/24 [01:12<00:18,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '0', 2) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [01:16<00:14,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '0', 3) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 21/24 [01:20<00:11,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '128', 0) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 22/24 [01:24<00:07,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '128', 1) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 23/24 [01:28<00:03,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '128', 2) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:32<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UC3', '128', 3) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ckpts={}\n",
    "\n",
    "project = \"peppina-final\"\n",
    "for k, name in tqdm(trial_names.items()):\n",
    "    ckpts[k] = {}\n",
    "    count=0\n",
    "    try: \n",
    "        dir = [f for f in base_path.rglob(f\"*{name}*/\")][0]\n",
    "    except:\n",
    "        continue\n",
    "    config = pickle.load((dir/\"params.pkl\").open(\"rb\"))\n",
    "    paths = [f for f in (dir/project).rglob(f\"*last.ckpt\")]\n",
    "    if len(paths)==0:\n",
    "        paths=[f for f in (dir/project).rglob(f\"*.ckpt\")]\n",
    "    ckpts[k] = {\n",
    "        'config': config,\n",
    "        'ckpts': paths\n",
    "    }\n",
    "    count+=len(ckpts[k][\"ckpts\"])\n",
    "    print(k, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 06:56:35,354\tINFO worker.py:1636 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17169\n",
      "loading  ppi_sensitivity/biogrid/2024-10/folds/random_sensitivity.pkl\n",
      "17169\n",
      "loading  ppi_sensitivity/biogrid/2024-10/folds/random_sensitivity.pkl\n",
      "17169\n",
      "loading  ppi_sensitivity/biogrid/2024-10/folds/protein_sensitivity.pkl\n",
      "17169\n",
      "loading  ppi_sensitivity/biogrid/2024-10/folds/protein_sensitivity.pkl\n",
      "17169\n",
      "loading  ppi_sensitivity/biogrid/2024-10/folds/model_sensitivity.pkl\n",
      "17169\n",
      "loading  ppi_sensitivity/biogrid/2024-10/folds/model_sensitivity.pkl\n"
     ]
    }
   ],
   "source": [
    "folds={}\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True, _temp_dir=\"/data/adipalma/tmp\")\n",
    "\n",
    "for hold_out_by in ['UC1','UC2','UC3']:\n",
    "    for embeddings_len in ['0','128']:#,'onehot']:\n",
    "        config=ckpts[(hold_out_by, embeddings_len, 0)]['config']\n",
    "        config['biogrid_ver'] = '2024-10'\n",
    "        folds[(hold_out_by,embeddings_len)] = create_fold_dict(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'specificity': specificity,\n",
    "    'auroc': auroc,\n",
    "    'recall': recall,\n",
    "    'precision': precision,\n",
    "    'f1': f1_score,\n",
    "    'mcc': matthews_corrcoef\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide cuda devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_predict(config, ckpt, hold_out_by, features):\n",
    "    fold = ray.get(folds[(hold_out_by, features)][0]\n",
    "                   [('sensitivity',config['hold_out_by']['grid_search'][0] if type(config['hold_out_by'])==dict else config['hold_out_by'])]\n",
    "                   [config['test_fold']])\n",
    "    \n",
    "    if 'aggr' not in config.keys():\n",
    "        config['aggr'] = config['SAGE_aggr']\n",
    "    if 'uniform_bound' not in config.keys():\n",
    "        config['uniform_bound'] = None\n",
    "    if 'weight_initializer' not in config.keys():\n",
    "        config['weight_initializer'] = 'kaiming_uniform'\n",
    "\n",
    "\n",
    "    test = fold['test']\n",
    "    outer_train = fold['train']\n",
    "    train = outer_train[config[\"val_fold\"]]['train']\n",
    "    val = outer_train[config[\"val_fold\"]]['val']\n",
    "    config['batch_size'] = 5000\n",
    "    \n",
    "    data = GraphDataModule(train, val, test, config)\n",
    "    data.setup()\n",
    "\n",
    "    input_dim = train[0].x.shape[1]\n",
    "    output_dim = 1\n",
    "    start = time.time()\n",
    "    model = GCN.load_from_checkpoint(ckpt, input_dim=input_dim, output_dim=output_dim, config=config,  map_location=torch.device('cpu'))\n",
    "    \n",
    "    cuda_args = {\"accelerator\": \"cpu\"}\n",
    "\n",
    "    trainer = Trainer(enable_progress_bar = False, **cuda_args)\n",
    "  \n",
    "    data = GraphDataModule(train, val, test, config)\n",
    "    data.setup()\n",
    "    end = time.time()\n",
    "    print(\"Time to load model: \", end-start)\n",
    "    start = time.time()\n",
    "    predictions = trainer.predict(model, data.test_dataloader())\n",
    "    end = time.time()\n",
    "    print(\"Time to predict: \", end-start)\n",
    "    # concatenate all predictions in a single tensor\n",
    "    predictions = torch.cat(predictions)\n",
    "    print(len(predictions), len(test))\n",
    "    \n",
    "    return predictions, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  4.85598611831665\n",
      "Time to predict:  3.9597575664520264\n",
      "4293 4293\n",
      "------------------------------------- class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "Time to load model:  5.884603023529053\n",
      "Time to predict:  10.930286407470703\n",
      "4292 4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  4.660712242126465\n",
      "Time to predict:  4.136009216308594\n",
      "4292 4292\n",
      "------------------------------------- class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "Time to load model:  5.0101094245910645\n",
      "Time to predict:  10.069069147109985\n",
      "4291 4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  4.867904186248779\n",
      "Time to predict:  6.18917179107666\n",
      "4293 4293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  4.769256114959717\n",
      "Time to predict:  4.200435638427734\n",
      "4292 4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  4.7747087478637695\n",
      "Time to predict:  4.204930543899536\n",
      "4292 4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  4.9301979541778564\n",
      "Time to predict:  4.2957470417022705\n",
      "4291 4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  5.047852993011475\n",
      "Time to predict:  4.843435287475586\n",
      "2895 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  5.023789882659912\n",
      "Time to predict:  4.608443975448608\n",
      "4433 4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "------------------------------------- class\n",
      "Time to load model:  5.106456995010376\n",
      "Time to predict:  3.8804540634155273\n",
      "3865 3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  5.162142992019653\n",
      "Time to predict:  4.113345623016357\n",
      "3398 3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "------------------------------------- class\n",
      "Time to load model:  5.143088340759277\n",
      "Time to predict:  1.9516239166259766\n",
      "2895 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  5.244577169418335\n",
      "Time to predict:  4.775022745132446\n",
      "4433 4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  5.255730152130127\n",
      "Time to predict:  3.1301584243774414\n",
      "3865 3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model:  5.340029954910278\n",
      "Time to predict:  2.153625726699829\n",
      "3398 3398\n",
      "------------------------------------- class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "Time to load model:  5.290875434875488\n",
      "Time to predict:  4.313160419464111\n",
      "3294 3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "------------------------------------- class\n",
      "Time to load model:  4.1762096881866455\n",
      "Time to predict:  3.7138452529907227\n",
      "3806 3806\n",
      "------------------------------------- class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "Time to load model:  4.461603879928589\n",
      "Time to predict:  9.414254188537598\n",
      "5590 5590\n",
      "------------------------------------- class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "Time to load model:  5.295984268188477\n",
      "Time to predict:  5.827144384384155\n",
      "4478 4479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "------------------------------------- class\n",
      "Time to load model:  5.224966764450073\n",
      "Time to predict:  3.2450878620147705\n",
      "3294 3294\n",
      "------------------------------------- class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "Time to load model:  5.360688924789429\n",
      "Time to predict:  3.9404585361480713\n",
      "3806 3806\n",
      "------------------------------------- class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "Time to load model:  4.347567558288574\n",
      "Time to predict:  10.358577728271484\n",
      "5590 5590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- class\n",
      "------------------------------------- class\n",
      "Time to load model:  4.133492469787598\n",
      "Time to predict:  2.315964698791504\n",
      "4478 4479\n"
     ]
    }
   ],
   "source": [
    "predictions_dict = {}\n",
    "for k,v in ckpts.items():\n",
    "    predictions_dict[k] = {}\n",
    "\n",
    "    if len(v['ckpts']) == 0:\n",
    "        print(f\"no checkpoint for {k} fold {k[2]}\")\n",
    "        continue\n",
    "    # print(v['config'], v['ckpts'][0], k[0], k[1])\n",
    "    try:\n",
    " \n",
    "        predictions = load_and_predict(v['config'], v['ckpts'][0], k[0], k[1])\n",
    "        predictions_dict[k] = predictions\n",
    "    except Exception as e:\n",
    "        print(f\"error for {k} fold {k[2]}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "pickle.dump(predictions_dict, open(\"predictions_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict=pickle.load(open(\"predictions_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(predictions, test, confidence_threshold=None):\n",
    "    stats = []\n",
    "    # print(len(predictions), len(test))\n",
    "    # print(type(test))\n",
    "    if confidence_threshold is not None:\n",
    "        probs = torch.sigmoid(predictions)\n",
    "        index = [i for i, p in enumerate(probs) if p < confidence_threshold or p > (1-confidence_threshold)]\n",
    "        test = [test[i] for i in index]   \n",
    "        predictions = predictions[index]     \n",
    "        if len(index) == 0:\n",
    "            print(\"no predictions\")\n",
    "            return None\n",
    "    \n",
    "    for i,d in enumerate(test):\n",
    "        if i >= len(predictions):\n",
    "            break\n",
    "        # convert the graph to networkx\n",
    "        g = to_networkx(d, remove_self_loops=True)\n",
    "        # print(g.edges())\n",
    "        # print(d['x'])\n",
    "        input_node = np.where(d['x'][:,0]==1)[0][0]\n",
    "        output_node = np.where(d['x'][:,1]==1)[0][0]\n",
    "        # print(input_node, output_node)\n",
    "        \n",
    "        def distance(g, input_node, output_node):\n",
    "            try: \n",
    "                return nx.shortest_path_length(g, source=input_node, target=output_node)\n",
    "            except: \n",
    "                return 0\n",
    "\n",
    "        stats.append({\n",
    "            'nodes': d['x'].shape[0],\n",
    "            'edges': d['edge_index'].shape[1] if d['edge_index'].shape[0] == 2 else 0,\n",
    "            'cc': nx.average_clustering(g),\n",
    "            'distance_io': distance(g, input_node, output_node),\n",
    "            'distance_oi': distance(g, output_node, input_node),\n",
    "            'input_centrality': nx.degree_centrality(g)[input_node],\n",
    "            'output_centrality': nx.degree_centrality(g)[output_node],\n",
    "        })\n",
    "\n",
    "    assert len(stats)==len(predictions)\n",
    "    df = pd.DataFrame(stats)\n",
    "    return df\n",
    "\n",
    "\n",
    "def metrics_from_predictions(predictions, test, confidence_threshold=None):\n",
    "    \n",
    "    df = compute_stats(predictions, test, confidence_threshold)\n",
    "    \n",
    "    metrics_dict = {}\n",
    "    for metric_name, fun in {'f1': f1_score}.items():\n",
    "        metrics_dict[metric_name] = {}\n",
    "        \n",
    "        def apply_metric(x):\n",
    "            preds = predictions[x.index]\n",
    "            labels = [d['y'] for d in [test[i] for i in x.index]]\n",
    "            return fun(preds, torch.IntTensor(labels), task='binary')\n",
    "        \n",
    "        for grouping, bins in {\n",
    "            'nodes': range(0, df.nodes.max(), 5),\n",
    "            'edges': range(0, df.edges.max(), 20),\n",
    "            'cc': [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "            'distance_io': range(8),\n",
    "            'distance_oi': range(8),\n",
    "        }.items():\n",
    "            if grouping not in ['distance_io', 'distance_oi']:\n",
    "                df[f\"{grouping}_bin\"] = pd.cut(df[grouping], bins=bins)\n",
    "                # set the bin id as the center of the bin\n",
    "                df[\"bin_id\"] = df[f\"{grouping}_bin\"].apply(lambda x: x.mid).astype(float)\n",
    "                metrics_dict[metric_name][f'by_{grouping}'] = df.groupby(\"bin_id\").apply(apply_metric)\n",
    "            else:\n",
    "                metrics_dict[metric_name][f'by_{grouping}'] = df.groupby(grouping).apply(apply_metric)\n",
    "            \n",
    "        metrics_dict[metric_name]['mean'] = apply_metric(df)\n",
    "\n",
    "    # print(by_nodes)\n",
    "\n",
    "    return metrics_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dicts = {}\n",
    "for k, v in predictions_dict.items():\n",
    "    metrics_dicts[k]= {}\n",
    "    metrics_dicts[k], df = metrics_from_predictions(*predictions_dict[k])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(metrics_dicts, open(\"metrics_dicts-2024-10.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dicts = pickle.load(open(\"metrics_dicts-2024-10.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dicts_aio = {}\n",
    "\n",
    "# concatenate the results from the different folds in one list\n",
    "for hold_out_by in ['UC1','UC2','UC3']:\n",
    "    for embeddings_len in ['0','128']:\n",
    "        metrics_dicts_aio[(hold_out_by,embeddings_len)] = {}\n",
    "        for metric in [\"f1\"]:\n",
    "            metrics_dicts_aio[(hold_out_by,embeddings_len)][metric] = {}\n",
    "            for grouping in [\"by_nodes\", \"by_edges\",'by_cc', 'by_distance_io', 'by_distance_oi']: #'by_input_centrality', 'by_output_centrality']:\n",
    "                if hold_out_by=='UC1' and embeddings_len=='0':\n",
    "                    metrics_dicts_aio[(hold_out_by,embeddings_len)][metric][grouping] = pd.concat([metrics_dicts[(hold_out_by, embeddings_len, fold)][metric][grouping] for fold in [0,1,2]]).groupby(level=0).mean()\n",
    "                else:\n",
    "                    metrics_dicts_aio[(hold_out_by,embeddings_len)][metric][grouping] = pd.concat([metrics_dicts[(hold_out_by, embeddings_len, fold)][metric][grouping] for fold in range(4)]).groupby(level=0).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['number of nodes', 'number of edges', 'clustering coefficient', 'I/O distance', 'O->I distance', 'input node centrality', 'ouptut node centrality']\n",
    "bys = ['by_nodes', 'by_edges', 'by_cc', 'by_distance_io', 'by_distance_oi', 'input_centrality', 'output_centrality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance tables for high-confidence predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m predictions_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     hc_metrics_dicts[k]\u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m():\n\u001b[1;32m      5\u001b[0m         metrics_dict\u001b[38;5;241m=\u001b[39mmetrics_from_predictions(\u001b[38;5;241m*\u001b[39mpredictions_dict[k][fold], confidence_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metrics_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "hc_metrics_dicts = {}\n",
    "for k,v in predictions_dict.items():\n",
    "    hc_metrics_dicts[k]= {}\n",
    "    for fold in v.keys():\n",
    "        metrics_dict=metrics_from_predictions(*predictions_dict[k][fold], confidence_threshold=1e-2)\n",
    "        if metrics_dict is not None:\n",
    "            hc_metrics_dicts[k][fold]=metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4291 4292\n",
      "<class 'list'>\n",
      "4292 4292\n",
      "<class 'list'>\n",
      "4292 4292\n",
      "<class 'list'>\n",
      "4293 4293\n",
      "<class 'list'>\n",
      "4292 4292\n",
      "<class 'list'>\n",
      "4291 4292\n",
      "<class 'list'>\n",
      "4293 4293\n",
      "<class 'list'>\n",
      "4292 4292\n",
      "<class 'list'>\n",
      "4292 4292\n",
      "<class 'list'>\n",
      "4293 4293\n",
      "<class 'list'>\n",
      "4292 4292\n",
      "<class 'list'>\n",
      "4291 4292\n",
      "<class 'list'>\n",
      "3398 3398\n",
      "<class 'list'>\n",
      "3865 3865\n",
      "<class 'list'>\n",
      "4433 4433\n",
      "<class 'list'>\n",
      "2895 2896\n",
      "<class 'list'>\n",
      "4433 4433\n",
      "<class 'list'>\n",
      "2895 2896\n",
      "<class 'list'>\n",
      "3398 3398\n",
      "<class 'list'>\n",
      "3865 3865\n",
      "<class 'list'>\n",
      "3398 3398\n",
      "<class 'list'>\n",
      "3865 3865\n",
      "<class 'list'>\n",
      "4433 4433\n",
      "<class 'list'>\n",
      "2895 2896\n",
      "<class 'list'>\n",
      "4478 4479\n",
      "<class 'list'>\n",
      "5590 5590\n",
      "<class 'list'>\n",
      "no predictions\n",
      "3806 3806\n",
      "<class 'list'>\n",
      "3294 3294\n",
      "<class 'list'>\n",
      "4478 4479\n",
      "<class 'list'>\n",
      "5590 5590\n",
      "<class 'list'>\n",
      "3806 3806\n",
      "<class 'list'>\n",
      "3294 3294\n",
      "<class 'list'>\n",
      "4478 4479\n",
      "<class 'list'>\n",
      "5590 5590\n",
      "<class 'list'>\n",
      "3806 3806\n",
      "<class 'list'>\n",
      "3294 3294\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "hc_metrics_dicts = {}\n",
    "threshold = 0.15\n",
    "for k,v in predictions_dict.items():\n",
    "    hc_metrics_dicts[k]= {}\n",
    "    for fold in v.keys():\n",
    "        metrics_dict=metrics_from_predictions(*predictions_dict[k][fold], confidence_threshold=threshold)\n",
    "        if metrics_dict is not None:\n",
    "            hc_metrics_dicts[k][fold]=metrics_dict\n",
    "\n",
    "for k,v in hc_metrics_dicts.items():\n",
    "    if len(v) == 0:\n",
    "        continue\n",
    "    try:\n",
    "        scatter_metrics(k,v, prefix=f\"hc{threshold}_metrics_wrt_graph_properties\")\n",
    "        line_plot_metrics(k,v, prefix=f\"hc{threshold}_metrics_wrt_graph_properties\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hc_metrics_dicts, open(f\"hc{threshold}_metrics_dicts.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_from_metrics_dicts(metrics_dicts):\n",
    "    table=[]\n",
    "    for k in metrics_dicts:\n",
    "        table.append({\n",
    "            'hold_out_by': k[0],\n",
    "            'features': k[1]\n",
    "        })\n",
    "        # print(len(metrics_dicts[k].keys()))\n",
    "        for metric in metrics:\n",
    "            # mean over the different folds\n",
    "            sum = 0\n",
    "            for fold in metrics_dicts[k].keys():\n",
    "                sum += metrics_dicts[k][fold][metric]['mean']\n",
    "            if len(metrics_dicts[k].keys()) > 0:\n",
    "                table[-1][metric] = sum/len(metrics_dicts[k].keys())\n",
    "            else:\n",
    "                table[-1][metric] = np.nan\n",
    "    return pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hold_out_by</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "      <th>auroc</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.8187)</td>\n",
       "      <td>tensor(0.8841)</td>\n",
       "      <td>tensor(0.8832)</td>\n",
       "      <td>tensor(0.6821)</td>\n",
       "      <td>tensor(0.7403)</td>\n",
       "      <td>tensor(0.7092)</td>\n",
       "      <td>tensor(0.5795)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random</td>\n",
       "      <td>128</td>\n",
       "      <td>tensor(0.8533)</td>\n",
       "      <td>tensor(0.8840)</td>\n",
       "      <td>tensor(0.9125)</td>\n",
       "      <td>tensor(0.7892)</td>\n",
       "      <td>tensor(0.7666)</td>\n",
       "      <td>tensor(0.7776)</td>\n",
       "      <td>tensor(0.6684)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random</td>\n",
       "      <td>onehot</td>\n",
       "      <td>tensor(0.8536)</td>\n",
       "      <td>tensor(0.9082)</td>\n",
       "      <td>tensor(0.9152)</td>\n",
       "      <td>tensor(0.7396)</td>\n",
       "      <td>tensor(0.8028)</td>\n",
       "      <td>tensor(0.7683)</td>\n",
       "      <td>tensor(0.6642)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protein</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.6212)</td>\n",
       "      <td>tensor(0.7933)</td>\n",
       "      <td>tensor(0.5872)</td>\n",
       "      <td>tensor(0.2649)</td>\n",
       "      <td>tensor(0.3736)</td>\n",
       "      <td>tensor(0.3022)</td>\n",
       "      <td>tensor(0.0636)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protein</td>\n",
       "      <td>128</td>\n",
       "      <td>tensor(0.7794)</td>\n",
       "      <td>tensor(0.8623)</td>\n",
       "      <td>tensor(0.8231)</td>\n",
       "      <td>tensor(0.5965)</td>\n",
       "      <td>tensor(0.6710)</td>\n",
       "      <td>tensor(0.6298)</td>\n",
       "      <td>tensor(0.4754)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>protein</td>\n",
       "      <td>onehot</td>\n",
       "      <td>tensor(0.7665)</td>\n",
       "      <td>tensor(0.8078)</td>\n",
       "      <td>tensor(0.8238)</td>\n",
       "      <td>tensor(0.6756)</td>\n",
       "      <td>tensor(0.6223)</td>\n",
       "      <td>tensor(0.6469)</td>\n",
       "      <td>tensor(0.4742)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.5903)</td>\n",
       "      <td>tensor(0.7576)</td>\n",
       "      <td>tensor(0.5596)</td>\n",
       "      <td>tensor(0.2436)</td>\n",
       "      <td>tensor(0.3365)</td>\n",
       "      <td>tensor(0.2513)</td>\n",
       "      <td>tensor(0.0058)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model</td>\n",
       "      <td>128</td>\n",
       "      <td>tensor(0.6719)</td>\n",
       "      <td>tensor(0.7859)</td>\n",
       "      <td>tensor(0.6386)</td>\n",
       "      <td>tensor(0.4323)</td>\n",
       "      <td>tensor(0.4928)</td>\n",
       "      <td>tensor(0.4594)</td>\n",
       "      <td>tensor(0.2272)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model</td>\n",
       "      <td>onehot</td>\n",
       "      <td>tensor(0.6921)</td>\n",
       "      <td>tensor(0.7919)</td>\n",
       "      <td>tensor(0.6509)</td>\n",
       "      <td>tensor(0.4841)</td>\n",
       "      <td>tensor(0.5271)</td>\n",
       "      <td>tensor(0.5033)</td>\n",
       "      <td>tensor(0.2829)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hold_out_by features        accuracy     specificity           auroc  \\\n",
       "0      random        0  tensor(0.8187)  tensor(0.8841)  tensor(0.8832)   \n",
       "1      random      128  tensor(0.8533)  tensor(0.8840)  tensor(0.9125)   \n",
       "2      random   onehot  tensor(0.8536)  tensor(0.9082)  tensor(0.9152)   \n",
       "3     protein        0  tensor(0.6212)  tensor(0.7933)  tensor(0.5872)   \n",
       "4     protein      128  tensor(0.7794)  tensor(0.8623)  tensor(0.8231)   \n",
       "5     protein   onehot  tensor(0.7665)  tensor(0.8078)  tensor(0.8238)   \n",
       "6       model        0  tensor(0.5903)  tensor(0.7576)  tensor(0.5596)   \n",
       "7       model      128  tensor(0.6719)  tensor(0.7859)  tensor(0.6386)   \n",
       "8       model   onehot  tensor(0.6921)  tensor(0.7919)  tensor(0.6509)   \n",
       "\n",
       "           recall       precision              f1             mcc  \n",
       "0  tensor(0.6821)  tensor(0.7403)  tensor(0.7092)  tensor(0.5795)  \n",
       "1  tensor(0.7892)  tensor(0.7666)  tensor(0.7776)  tensor(0.6684)  \n",
       "2  tensor(0.7396)  tensor(0.8028)  tensor(0.7683)  tensor(0.6642)  \n",
       "3  tensor(0.2649)  tensor(0.3736)  tensor(0.3022)  tensor(0.0636)  \n",
       "4  tensor(0.5965)  tensor(0.6710)  tensor(0.6298)  tensor(0.4754)  \n",
       "5  tensor(0.6756)  tensor(0.6223)  tensor(0.6469)  tensor(0.4742)  \n",
       "6  tensor(0.2436)  tensor(0.3365)  tensor(0.2513)  tensor(0.0058)  \n",
       "7  tensor(0.4323)  tensor(0.4928)  tensor(0.4594)  tensor(0.2272)  \n",
       "8  tensor(0.4841)  tensor(0.5271)  tensor(0.5033)  tensor(0.2829)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_from_metrics_dicts(metrics_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hold_out_by</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "      <th>auroc</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.9110)</td>\n",
       "      <td>tensor(0.9510)</td>\n",
       "      <td>tensor(0.9239)</td>\n",
       "      <td>tensor(0.8012)</td>\n",
       "      <td>tensor(0.8618)</td>\n",
       "      <td>tensor(0.8299)</td>\n",
       "      <td>tensor(0.7709)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random</td>\n",
       "      <td>128</td>\n",
       "      <td>tensor(0.9185)</td>\n",
       "      <td>tensor(0.9454)</td>\n",
       "      <td>tensor(0.9388)</td>\n",
       "      <td>tensor(0.8552)</td>\n",
       "      <td>tensor(0.8692)</td>\n",
       "      <td>tensor(0.8621)</td>\n",
       "      <td>tensor(0.8044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random</td>\n",
       "      <td>onehot</td>\n",
       "      <td>tensor(0.9223)</td>\n",
       "      <td>tensor(0.9575)</td>\n",
       "      <td>tensor(0.9388)</td>\n",
       "      <td>tensor(0.8299)</td>\n",
       "      <td>tensor(0.8912)</td>\n",
       "      <td>tensor(0.8591)</td>\n",
       "      <td>tensor(0.8065)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protein</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.9155)</td>\n",
       "      <td>tensor(0.9958)</td>\n",
       "      <td>tensor(0.2265)</td>\n",
       "      <td>tensor(0.0458)</td>\n",
       "      <td>tensor(0.1774)</td>\n",
       "      <td>tensor(0.0728)</td>\n",
       "      <td>tensor(0.6237)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protein</td>\n",
       "      <td>128</td>\n",
       "      <td>tensor(0.8676)</td>\n",
       "      <td>tensor(0.9396)</td>\n",
       "      <td>tensor(0.8537)</td>\n",
       "      <td>tensor(0.6384)</td>\n",
       "      <td>tensor(0.7779)</td>\n",
       "      <td>tensor(0.6941)</td>\n",
       "      <td>tensor(0.6200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>protein</td>\n",
       "      <td>onehot</td>\n",
       "      <td>tensor(0.8150)</td>\n",
       "      <td>tensor(0.8526)</td>\n",
       "      <td>tensor(0.8536)</td>\n",
       "      <td>tensor(0.7269)</td>\n",
       "      <td>tensor(0.6895)</td>\n",
       "      <td>tensor(0.7074)</td>\n",
       "      <td>tensor(0.5723)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.5166)</td>\n",
       "      <td>tensor(0.6588)</td>\n",
       "      <td>tensor(0.5509)</td>\n",
       "      <td>tensor(0.3419)</td>\n",
       "      <td>tensor(0.1014)</td>\n",
       "      <td>tensor(0.0854)</td>\n",
       "      <td>tensor(0.0095)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model</td>\n",
       "      <td>128</td>\n",
       "      <td>tensor(0.7538)</td>\n",
       "      <td>tensor(0.9163)</td>\n",
       "      <td>tensor(0.5650)</td>\n",
       "      <td>tensor(0.2813)</td>\n",
       "      <td>tensor(0.5777)</td>\n",
       "      <td>tensor(0.3598)</td>\n",
       "      <td>tensor(0.2594)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model</td>\n",
       "      <td>onehot</td>\n",
       "      <td>tensor(0.7260)</td>\n",
       "      <td>tensor(0.8420)</td>\n",
       "      <td>tensor(0.6421)</td>\n",
       "      <td>tensor(0.4659)</td>\n",
       "      <td>tensor(0.5707)</td>\n",
       "      <td>tensor(0.5116)</td>\n",
       "      <td>tensor(0.3277)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hold_out_by features        accuracy     specificity           auroc  \\\n",
       "0      random        0  tensor(0.9110)  tensor(0.9510)  tensor(0.9239)   \n",
       "1      random      128  tensor(0.9185)  tensor(0.9454)  tensor(0.9388)   \n",
       "2      random   onehot  tensor(0.9223)  tensor(0.9575)  tensor(0.9388)   \n",
       "3     protein        0  tensor(0.9155)  tensor(0.9958)  tensor(0.2265)   \n",
       "4     protein      128  tensor(0.8676)  tensor(0.9396)  tensor(0.8537)   \n",
       "5     protein   onehot  tensor(0.8150)  tensor(0.8526)  tensor(0.8536)   \n",
       "6       model        0  tensor(0.5166)  tensor(0.6588)  tensor(0.5509)   \n",
       "7       model      128  tensor(0.7538)  tensor(0.9163)  tensor(0.5650)   \n",
       "8       model   onehot  tensor(0.7260)  tensor(0.8420)  tensor(0.6421)   \n",
       "\n",
       "           recall       precision              f1             mcc  \n",
       "0  tensor(0.8012)  tensor(0.8618)  tensor(0.8299)  tensor(0.7709)  \n",
       "1  tensor(0.8552)  tensor(0.8692)  tensor(0.8621)  tensor(0.8044)  \n",
       "2  tensor(0.8299)  tensor(0.8912)  tensor(0.8591)  tensor(0.8065)  \n",
       "3  tensor(0.0458)  tensor(0.1774)  tensor(0.0728)  tensor(0.6237)  \n",
       "4  tensor(0.6384)  tensor(0.7779)  tensor(0.6941)  tensor(0.6200)  \n",
       "5  tensor(0.7269)  tensor(0.6895)  tensor(0.7074)  tensor(0.5723)  \n",
       "6  tensor(0.3419)  tensor(0.1014)  tensor(0.0854)  tensor(0.0095)  \n",
       "7  tensor(0.2813)  tensor(0.5777)  tensor(0.3598)  tensor(0.2594)  \n",
       "8  tensor(0.4659)  tensor(0.5707)  tensor(0.5116)  tensor(0.3277)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_from_metrics_dicts(hc_metrics_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most significant plots (export for article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance w.r.t. CC, nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_fonts(ax, skip_artists=2):\n",
    "    ax.legend(['I/O', 'I/O+emb', '',''])\n",
    "    artists = ax.legend_.legendHandles\n",
    "    # remove the error bars from the legend\n",
    "    artists = [artist for i, artist in enumerate(artists) if i%skip_artists==0]\n",
    "    ax.legend(artists, ['I/O', 'I/O+emb'], loc='upper right', prop={'size': 20}, )\n",
    "    # set the legend background alpha\n",
    "    ax.legend_.get_frame().set_alpha(0.4)\n",
    "\n",
    "    # increase the font of axis labels and legend\n",
    "    for item in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(16)\n",
    "    for item in [ax.title, ax.xaxis.label, ax.yaxis.label]:\n",
    "        item.set_fontsize(24)\n",
    "    # avoid cutting exis title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3787133/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n"
     ]
    }
   ],
   "source": [
    "# plot the mcc w.r.t. the number of nodes, edges and cc with a regplot\n",
    "# for by in ['by_nodes', 'by_edges', 'by_cc']:\n",
    "for by in ['by_cc','by_nodes','by_edges']:\n",
    "    for metric in ['f1']:\n",
    "        for hold_out_by in ['UC1','UC2','UC3']:\n",
    "            fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "            for embeddings_len in ['0', '128']:\n",
    "                data=[]\n",
    "                for fold in range(4):\n",
    "                    data.append(metrics_dicts[(hold_out_by,embeddings_len,fold)][metric][by].sort_index())\n",
    "                data = pd.concat(data, axis=1)\n",
    "                data = data.mean(axis=1)\n",
    "\n",
    "                sns.regplot(x=data.index, y=np.array(data, dtype=float), ax=ax, order=2)\n",
    "                \n",
    "                ax.set_ylim([0,1])\n",
    "                ax.set_ylabel(metric.upper())\n",
    "                ax.set_xlabel(by.replace('by_',''))\n",
    "                \n",
    "                if by == 'by_cc':\n",
    "                    ax.set_xlim([0,1])\n",
    "                elif by == 'by_nodes':\n",
    "                    ax.set_xlim([2,None])\n",
    "                elif by == 'by_edges':\n",
    "                    ax.set_xlim([1,None])\n",
    "\n",
    "                fig.tight_layout(pad=3.0)\n",
    "                \n",
    "            set_fonts(ax, skip_artists=3)\n",
    "            plt.savefig(f'figures_2024-10/f1_{by}_{hold_out_by}.pdf', format='pdf')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n"
     ]
    }
   ],
   "source": [
    "# plot the mcc w.r.t. the number of nodes, edges and cc with a regplot\n",
    "for by in ['by_nodes', 'by_edges']:\n",
    "    for metric in ['f1']:\n",
    "        for hold_out_by in ['UC1','UC2','UC3']:\n",
    "            fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "            for embeddings_len in ['0', '128']:\n",
    "                data=[]\n",
    "                for fold in (range(4) if not (hold_out_by=='UC1' and embeddings_len=='0') else [0,1,2]):\n",
    "                    data.append(metrics_dicts[(hold_out_by,embeddings_len,fold)][metric][by].sort_index())\n",
    "                data = pd.concat(data, axis=1)\n",
    "                data = data.mean(axis=1)\n",
    "                # group samples in bins\n",
    "                data = data.groupby(pd.cut(data.index, bins=20)).mean()\n",
    "                # convert the intevals in the middle of the interval\n",
    "                data.index = [(i.left+i.right)/2 for i in data.index]\n",
    "                # sns.regplot(x=data.index, y=np.array(data, dtype=float), ax=ax, order=2)\n",
    "                # plot the moving average\n",
    "                avg_data = data.rolling(window=3)\n",
    "                # smooth the data\n",
    "                ax.plot(avg_data.mean())\n",
    "                # plot also the standard deviation of the moving average\n",
    "                ax.fill_between(data.index, avg_data.mean() - avg_data.std(), avg_data.mean() + avg_data.std(), alpha=0.2)\n",
    "                ax.set_ylabel(metric.upper())\n",
    "                ax.set_xlabel(by.replace('by_',''))\n",
    "                # ax.set_title(f'{metric} w.r.t. {by}')\n",
    "\n",
    "                fig.tight_layout(pad=3.0)\n",
    "                \n",
    "            set_fonts(ax)\n",
    "            plt.savefig(f'figures_2024-10/f1_{by}_{hold_out_by}.pdf', format='pdf')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance w.r.t. I->O and O->I distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/home/a.dipalma9/gnn_on_ppi/venv/lib/python3.8/site-packages/seaborn/algorithms.py:100: RankWarning: Polyfit may be poorly conditioned\n",
      "  boot_dist.append(f(*sample, **func_kwargs))\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n",
      "/tmp/ipykernel_3605704/1496000574.py:3: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  artists = ax.legend_.legendHandles\n"
     ]
    }
   ],
   "source": [
    "# plot the f1 score w.r.t. I->O distance one a line plot, averaging over the folds and showing the standard deviation\n",
    "for direction in ['io', 'oi']:\n",
    "    for hold_out_by in ['UC1','UC2','UC3']:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "        for embeddings_len in ['0', '128']:\n",
    "            data = []\n",
    "            for fold in range(4):\n",
    "                data.append(metrics_dicts[(hold_out_by,embeddings_len,fold)]['f1'][f'by_distance_{direction}'].sort_index())\n",
    "            data = pd.concat(data, axis=1)\n",
    "            means = data.mean(axis=1).sort_index()\n",
    "            stds =  data.std(axis=1).sort_index()\n",
    "            # ax.plot(means, label=k)\n",
    "            # replace inf and nans with 0\n",
    "            index = means.index\n",
    "            stds = np.array(stds, dtype=float)\n",
    "            means = np.array(means, dtype=float)\n",
    "            # ax.fill_between(index, means - stds, means + stds, alpha=0.2)\n",
    "            ax.set_ylim([0,1.1])\n",
    "            # ax.set_title(f'f1 w.r.t. I->O distance')\n",
    "            ax.set_ylabel('F1')\n",
    "            fig.tight_layout(pad=3.0)\n",
    "            # increase font size\n",
    "            ax.set_xlim([1,7])\n",
    "            \n",
    "            sns.regplot(x=index, y=means, ax=ax, scatter=True, order=2)\n",
    "            ax.set_xlabel('Path length from $u_{in}$ to $u_{out}$')\n",
    "        \n",
    "        set_fonts(ax, skip_artists=3)\n",
    "        \n",
    "        plt.savefig(f'figures_2024-10/f1_by_distance_{direction}_{hold_out_by}.pdf', format='pdf')\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
